背景:  
    需要对内容进行质量打标工作.在项目初期.标签并未十分完善,标签量较少.单个标签的覆盖范围比较大.可以通过一些关键词或其他特征来实现标签匹配.实现部分替代人工.  
    作为前期实验,项目内代码仅是通过数据试跑,并未在线上正式运行.处理的数据体量为:3万+书籍,52734文本.  
    
    
过程:  
    1.数据整理.书籍名称和作者缺少数据规范.数据格式不统一.通过收集标点符号,使用通配符统一格式后.再建立屏蔽词库.对书名中常见的无效数据(例如图书版别)进行清洗.  
    2.收集自定义字词,建立jieba分词的书名自定义字典.经过格式统一后,可以获取一些较为准确的书名词.这些词汇核对后作为jieba自定义词库的第一批数据.  
    3.整理分词,使用自定义字典对书籍进行分词.人工介入评估和筛选标签.补充到自定义词库.不断的重复这部分工作.直至出现的书籍全部处理完毕.  
    4.合并分词,用自定义字典对书籍的商品名/原名/译名进行分词.把分词结果合并.作为该书名的特征.  
    5.合并相同/相似书籍,用单个书名特征匹配,寻找全部数据中包含该特征的书名.包含则视同是同名异译的书.  
    6.建立书籍标签映射,通过书籍分类和标签的映射关系,建立书籍分类和标签做的映射.  
    7.建立书籍标签库,把书籍信息和映射合并.生成书名-包含分词-ID-标签的书籍标签表格.  
    8.获取帖子映射关系.从书籍标签库中获取 ID-标签 作为书籍ID的映射关系.获取书名分词-标签 作书名分词的映射关系.  
    注:书名分词是书名的一部分.最重要的部分,比如哈利-波特与火焰杯.分词可能就是 哈利-波特,火焰杯   
    9.帖子匹配标签.先对帖子做划分,划分为有书籍ID的和无书籍ID的.有书籍ID的通过书籍ID的映射匹配标签.无法匹配到标签的.再用标题和正文通过先分词后匹配来匹配标签.  
    无书籍ID的则直接通过标题和正文匹配标签.  


结果:  
    52734条文本,共有31069条数据匹配到标签,匹配率是58.91%.其中有书籍ID的匹配到15747条,无书籍ID的匹配到6908条.  
    通过随机抽取3%左右的数据,抽取1524条数据,其中888条匹配到标签,其中215条匹配的标签有误.准确率是75.27%  
    
思路流程图  
![思路流程图](https://raw.githubusercontent.com/gcm1994002/work/main/img/%E6%A0%87%E7%AD%BE%E5%8C%B9%E9%85%8D%E6%80%9D%E8%B7%AF%E6%B5%81%E7%A8%8B%E5%9B%BE.png)

